{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from lxml import html\n",
    "from lxml import etree\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtem_soup(url):\n",
    "    \"\"\"Obtem o objeto Soup para o artigo\n",
    "    Recebe:\n",
    "            url :: str\n",
    "    Retorna:\n",
    "            soup :: bs4.BeautifulSoup\n",
    "    \"\"\"\n",
    "    \n",
    "    headers = {'User-Agent': \n",
    "               'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "    html_texto = requests.get(url, headers=headers).text\n",
    "    soup = BeautifulSoup(html_texto, 'html.parser')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processa_seletor(sel_bruto):\n",
    "    \"\"\"Processa a string bruta do seletor de CSS obtida no site para\n",
    "    compatibilidade com a sitaxe esperada pelo Python/BeautifullSoup\"\"\"\n",
    "    \n",
    "    sel_processado = sel_bruto.replace('nth-child', 'nth-of-type')\n",
    "    return sel_processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valor_int(str_valor):\n",
    "    \"\"\"Converte o valor da bolsa de string para float.\n",
    "    Recebe:\n",
    "            str_valor_usd :: str\n",
    "    Retorna:\n",
    "            valor_int :: int\n",
    "    \"\"\"\n",
    "    chars_a_remover = ['$', 'U', 'S', ',', ' ']\n",
    "    valor_inteiro = ''.join([char for char in str_valor if char not in chars_a_remover])\n",
    "    return valor_inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_novas_linhas(str_bruta, sep='|'):\n",
    "    \"\"\"Remove novas linhas em excesso e \n",
    "    devolve uma string com separador=sep.\n",
    "    Recebe:\n",
    "            str_bruta :: str\n",
    "    Retorna:\n",
    "            str_proc  :: str\n",
    "            \n",
    "    Exemplo:\n",
    "        str_bruta = '\\n\\nCampo 1:\\n\\n\\nValor 1\\n\\nValor2\\n\\n\\n'\n",
    "        str_proc = '|Campo 1:|Valor 1|Valor2|'\n",
    "    \"\"\"\n",
    "    return re.sub('\\n+', sep, str_bruta).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cabecalho(soup, sel_raiz):\n",
    "    \"\"\"Parse do cabecalho, Titulo e Investigators\n",
    "    Recebe: \n",
    "            soup do artigo\n",
    "            seletor css para o artigo\n",
    "    Retorna:\n",
    "            Titulo :: str\n",
    "            Investigator :: str\n",
    "    \"\"\"\n",
    "    # Processa o seletor de CSS:\n",
    "    sel_tronco =  'section > div:nth-child(1) > div > div > div > div > div'\n",
    "    sel_css_titulo = processa_seletor(f'{sel_raiz} > {sel_tronco} > h1')\n",
    "    sel_css_instituicao = processa_seletor(f'{sel_raiz} > {sel_tronco} > div > p')\n",
    "    \n",
    "    # Obtem o titulo e o investigador\n",
    "    titulo = soup.select(sel_css_titulo)[0].text\n",
    "    \n",
    "    investigador_bruto = soup.select(sel_css_instituicao)[0].text\n",
    "    investigador = investigador_bruto.split(':')[1].strip()\n",
    "    \n",
    "    return {'titulo': titulo, 'instituicao': investigador}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_valor(soup, sel_raiz):\n",
    "    \"\"\"Parse do Data de Inicio, Valor da bolsa\n",
    "    Recebe: \n",
    "            soup do artigo\n",
    "            seletor css para o artigo\n",
    "    Retorna:\n",
    "            Data :: str\n",
    "            Valor :: str\n",
    "    \"\"\"\n",
    "    # Processa o seletor de CSS:\n",
    "    sel_tronco =  'section > div:nth-child(2)'\n",
    "    sel_css_data = processa_seletor(f'{sel_raiz} > {sel_tronco} > div:nth-child(1)')\n",
    "    sel_css_valor = processa_seletor(f'{sel_raiz} > {sel_tronco} > div:nth-child(2)')\n",
    "    \n",
    "    # Obtem a data inicial e o valor\n",
    "    data_ini_bruta = soup.select(sel_css_data)[0].text\n",
    "    data_ini = remove_novas_linhas(data_ini_bruta, sep='|').split('|')[2]\n",
    "    \n",
    "    valor_bruto = soup.select(sel_css_valor)[0].text\n",
    "    valor_str  = remove_novas_linhas(valor_bruto, sep='|').split('|')[2]\n",
    "    valor_num = valor_int(valor_str)\n",
    "    \n",
    "    return {'data_ini': data_ini, 'valor_bolsa': valor_num}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_descricao_detalhada(soup, sel_raiz):\n",
    "    \"\"\"Parse da descricao detalhada \n",
    "    Recebe: \n",
    "            soup do artigo\n",
    "            seletor css para o artigo\n",
    "    Retorna:\n",
    "            descricao_detalhada :: str\n",
    "    \"\"\"\n",
    "    # Processa o seletor de CSS:\n",
    "    sel_tronco =  'section > div:nth-child(3) > div > div > div > div > div > div'\n",
    "    sel_css_descr_det = processa_seletor(f'{sel_raiz} > {sel_tronco}')\n",
    "    \n",
    "    # Obtem a data inicial e o valor\n",
    "    descricao_detalhada_bruta = soup.select(sel_css_descr_det)[0].text\n",
    "    descricao_detalhada = remove_novas_linhas(descricao_detalhada_bruta, sep='\\n')\n",
    "  \n",
    "    return {'descr_detalhada': descricao_detalhada}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_artigo(soup, sel_raiz_artigo):\n",
    "    \"\"\"Parse completo do artigo \n",
    "    Recebe: \n",
    "            soup do artigo\n",
    "            seletor css para o artigo\n",
    "    Retorna:\n",
    "            json contendo as seguintes informacoes:\n",
    "                titulo :: str\n",
    "                instituicao :: str\n",
    "                data_ini :: str\n",
    "                valor_bolsa :: int (USD)\n",
    "                descricao_detalhada :: str\n",
    "    \"\"\"\n",
    "    campos = {}\n",
    "    \n",
    "    # Obtem titulo e instituicao\n",
    "    campos.update(parse_cabecalho(soup, sel_css_artigo))\n",
    "    \n",
    "    # Obtem data_ini e valor\n",
    "    campos.update(parse_data_valor(soup, sel_css_artigo))\n",
    "    \n",
    "    # Obtem descr_detalhada\n",
    "    campos.update(parse_descricao_detalhada(soup, sel_css_artigo))\n",
    "    \n",
    "    json_campos = json.loads(json.dumps(campos))\n",
    "    return json_campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://erefdn.org/research-grants-projects/currently-funded-projects'\n",
    "url_artigo = 'https://erefdn.org/non-recyclable-plastics-to-pavements/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_css_artigo = '#post-14369'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"titulo\": \"Non-Recyclable Plastics to Pavements\",\n",
      "    \"instituicao\": \"University of Illinois Urbana-Champaign\",\n",
      "    \"data_ini\": \"TBD\",\n",
      "    \"valor_bolsa\": \"161075\",\n",
      "    \"descr_detalhada\": \"This proposal seeks to create high-value and high-volume products from plastic waste for bitumen (asphalt binder) replacement in pavements. The bitumen replacement market is a potential repurposing for large quantities of waste plastics. It addresses an urgent economic and environmental need for plastic recycling as well as the transportation industry. With 4-5% replacement of bitumen, this market has the potential to consume 1 million tons of waste plastics out of the 26 million tons that go to landfills in the US. Also, the study goal is aligned with the global emphasis on enhancing transportation infrastructure sustainability. Moreover, asphalt pavements are 100% recyclable; therefore, plastic waste will remain in a recycling circular loop. Plastic waste, from landfill destined municipal solid waste (MSW), will be formulated for incorporation in bitumen that meets specified rheological and mechanical performance. Through manipulation of the chemical and molecular composition of waste plastics, current challenges, including sorting and processing of different plastics, storage instability and compatibility between bitumen and various plastics will be addressed.\\nThe objectives of this study are as follows:\\nDevelop compatibility and blending methodology of various plastic waste plastic for bitumen modification.\\nInvestigate the suitability of plastic types and mixed plastics for modifying bitumen.\\nDetermine the storage stability of plastic waste modified bitumen.\\nPerform chemical and rheological characterization of plastic-modified bitumen.\\nQuantify environmental benefits using life cycle assessment (LCA) for plastic-modified bitumen.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "soup = obtem_soup(url_artigo)\n",
    "json_artigo = parse_artigo(soup, sel_css_artigo)\n",
    "print(json.dumps(json_artigo, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bolsa():\n",
    "    def __init__(self, url):\n",
    "        self.titulo = ''\n",
    "        self.data_inicio = ''\n",
    "        self.valor_bolsa = ''\n",
    "        self.site_origem = url\n",
    "        self.descicao_detalhada = ''\n",
    "        \n",
    "    def obtem_dados(self):\n",
    "        pass\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
