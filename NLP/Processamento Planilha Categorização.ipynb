{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos de classificação com a planilha de oportunidades em texto\n",
    "\n",
    "https://github.com/jairoalves/mcti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arq = r\"C:\\Users\\u495\\GitHub\\MCTI\\NLP\\dados\\entrada\\oportunidades_classificacao.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(arq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>opo_brazil</th>\n",
       "      <th>clas</th>\n",
       "      <th>opo_titulo</th>\n",
       "      <th>opo_deadline</th>\n",
       "      <th>codigo</th>\n",
       "      <th>opo_texto</th>\n",
       "      <th>opo_tipo</th>\n",
       "      <th>atualizacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://royalsociety.org/grants-schemes-awards...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>APEX Award</td>\n",
       "      <td>28 October 2021</td>\n",
       "      <td>royal_210223_01_014</td>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>other</td>\n",
       "      <td>210223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://royalsociety.org/grants-schemes-awards...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Dorothy Hodgkin Fellowship</td>\n",
       "      <td>10 November 2021</td>\n",
       "      <td>royal_210223_01_015</td>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>fellowship</td>\n",
       "      <td>210223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://royalsociety.org/grants-schemes-awards...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>International Exchanges Scheme Standard round one</td>\n",
       "      <td>10 March 2021</td>\n",
       "      <td>royal_210223_01_001</td>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>other</td>\n",
       "      <td>210223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://royalsociety.org/grants-schemes-awards...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>JSPS Postdoctoral Fellowship</td>\n",
       "      <td>10 March 2021</td>\n",
       "      <td>royal_210223_01_002</td>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>fellowship</td>\n",
       "      <td>210223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://royalsociety.org/grants-schemes-awards...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Lisa Jardine Grant scheme round one</td>\n",
       "      <td>17 March 2021</td>\n",
       "      <td>royal_210223_01_000</td>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>grant</td>\n",
       "      <td>210223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://royalsociety.org/grants-schemes-awards...</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Royal Society Wolfson Fellowship round one</td>\n",
       "      <td>17 March 2021</td>\n",
       "      <td>royal_210223_01_003</td>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>fellowship</td>\n",
       "      <td>210223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://royalsociety.org/grants-schemes-awards...</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Royal Society Wolfson Visiting Fellowship roun...</td>\n",
       "      <td>17 March 2021</td>\n",
       "      <td>royal_210223_01_004</td>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>fellowship</td>\n",
       "      <td>210223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://royalsociety.org/grants-schemes-awards...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Short Industry Fellowship round one</td>\n",
       "      <td>27 May 2021</td>\n",
       "      <td>royal_210223_01_006</td>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>fellowship</td>\n",
       "      <td>210223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://royalsociety.org/grants-schemes-awards...</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>University Research Fellowship</td>\n",
       "      <td>7 September 2021</td>\n",
       "      <td>royal_210223_01_011</td>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>fellowship</td>\n",
       "      <td>210223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://wellcome.org/grant-funding/schemes/bio...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Biomedical Resource Grants</td>\n",
       "      <td>Preliminary application deadline12 January 202...</td>\n",
       "      <td>wellcome_210304_01_028</td>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant</td>\n",
       "      <td>210304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://wellcome.org/grant-funding/schemes/col...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Collaborative Awards in Science</td>\n",
       "      <td>Preliminary application deadline18 August 2020...</td>\n",
       "      <td>wellcome_210304_01_002</td>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>other</td>\n",
       "      <td>210304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://wellcome.org/grant-funding/schemes/doc...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Doctoral Studentships</td>\n",
       "      <td>Application deadline2 March 2021, 17:00 GMT, D...</td>\n",
       "      <td>wellcome_210304_01_007</td>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>other</td>\n",
       "      <td>210304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://wellcome.org/grant-funding/schemes/inn...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Innovator Awards</td>\n",
       "      <td>Full application deadline1 December 2020, 17:0...</td>\n",
       "      <td>wellcome_210304_01_005</td>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>other</td>\n",
       "      <td>210304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://wellcome.org/grant-funding/schemes/int...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>International Intermediate Fellowships</td>\n",
       "      <td>Preliminary application deadline5 November 202...</td>\n",
       "      <td>wellcome_210304_01_013</td>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>fellowship</td>\n",
       "      <td>210304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 link opo_brazil clas  \\\n",
       "0   https://royalsociety.org/grants-schemes-awards...          N    N   \n",
       "1   https://royalsociety.org/grants-schemes-awards...          N    N   \n",
       "2   https://royalsociety.org/grants-schemes-awards...          N    N   \n",
       "3   https://royalsociety.org/grants-schemes-awards...          N    N   \n",
       "4   https://royalsociety.org/grants-schemes-awards...          N    N   \n",
       "5   https://royalsociety.org/grants-schemes-awards...          N    Y   \n",
       "6   https://royalsociety.org/grants-schemes-awards...          N    Y   \n",
       "7   https://royalsociety.org/grants-schemes-awards...          N    N   \n",
       "8   https://royalsociety.org/grants-schemes-awards...          N    Y   \n",
       "9   https://wellcome.org/grant-funding/schemes/bio...          Y    Y   \n",
       "10  https://wellcome.org/grant-funding/schemes/col...          Y    Y   \n",
       "11  https://wellcome.org/grant-funding/schemes/doc...          Y    Y   \n",
       "12  https://wellcome.org/grant-funding/schemes/inn...          Y    Y   \n",
       "13  https://wellcome.org/grant-funding/schemes/int...          Y    Y   \n",
       "\n",
       "                                           opo_titulo  \\\n",
       "0                                          APEX Award   \n",
       "1                          Dorothy Hodgkin Fellowship   \n",
       "2   International Exchanges Scheme Standard round one   \n",
       "3                        JSPS Postdoctoral Fellowship   \n",
       "4                 Lisa Jardine Grant scheme round one   \n",
       "5          Royal Society Wolfson Fellowship round one   \n",
       "6   Royal Society Wolfson Visiting Fellowship roun...   \n",
       "7                 Short Industry Fellowship round one   \n",
       "8                      University Research Fellowship   \n",
       "9                          Biomedical Resource Grants   \n",
       "10                    Collaborative Awards in Science   \n",
       "11                              Doctoral Studentships   \n",
       "12                                   Innovator Awards   \n",
       "13            International Intermediate Fellowships    \n",
       "\n",
       "                                         opo_deadline                  codigo  \\\n",
       "0                                     28 October 2021     royal_210223_01_014   \n",
       "1                                    10 November 2021     royal_210223_01_015   \n",
       "2                                       10 March 2021     royal_210223_01_001   \n",
       "3                                       10 March 2021     royal_210223_01_002   \n",
       "4                                       17 March 2021     royal_210223_01_000   \n",
       "5                                       17 March 2021     royal_210223_01_003   \n",
       "6                                       17 March 2021     royal_210223_01_004   \n",
       "7                                         27 May 2021     royal_210223_01_006   \n",
       "8                                    7 September 2021     royal_210223_01_011   \n",
       "9   Preliminary application deadline12 January 202...  wellcome_210304_01_028   \n",
       "10  Preliminary application deadline18 August 2020...  wellcome_210304_01_002   \n",
       "11  Application deadline2 March 2021, 17:00 GMT, D...  wellcome_210304_01_007   \n",
       "12  Full application deadline1 December 2020, 17:0...  wellcome_210304_01_005   \n",
       "13  Preliminary application deadline5 November 202...  wellcome_210304_01_013   \n",
       "\n",
       "                                            opo_texto    opo_tipo  atualizacao  \n",
       "0   Skip to contentGo\\n                        Sea...       other       210223  \n",
       "1   Skip to contentGo\\n                        Sea...  fellowship       210223  \n",
       "2   Skip to contentGo\\n                        Sea...       other       210223  \n",
       "3   Skip to contentGo\\n                        Sea...  fellowship       210223  \n",
       "4   Skip to contentGo\\n                        Sea...       grant       210223  \n",
       "5   Skip to contentGo\\n                        Sea...  fellowship       210223  \n",
       "6   Skip to contentGo\\n                        Sea...  fellowship       210223  \n",
       "7   Skip to contentGo\\n                        Sea...  fellowship       210223  \n",
       "8   Skip to contentGo\\n                        Sea...  fellowship       210223  \n",
       "9   Grant Funding/Schemes/                        ...       grant       210304  \n",
       "10  Grant Funding/Schemes/                        ...       other       210304  \n",
       "11  Grant Funding/Schemes/                        ...       other       210304  \n",
       "12  Grant Funding/Schemes/                        ...       other       210304  \n",
       "13  Grant Funding/Schemes/                        ...  fellowship       210304  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis de interesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Coleta das variáveis de interesse\n",
    "X = df[['opo_texto']].copy()\n",
    "y = df['clas'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentenca():\n",
    "\n",
    "    def __init__(self, sentenca):\n",
    "        self.sent_bruta = sentenca\n",
    "        self.preproc()\n",
    "    \n",
    "    def remove_caracteres_nao_alfanumericos(self):\n",
    "        # padroes para trechos nao alfanumericos\n",
    "        ptn_nao_alfanum = r\"[\\W+]\"\n",
    "        self.sent_preproc = re.sub(ptn_nao_alfanum, ' ', self.sent_bruta)\n",
    "    \n",
    "    def remove_espacos_multiplos(self):\n",
    "        ptn_espacos_mult = r\"\\s+\"  \n",
    "        self.sent_preproc = re.sub(ptn_espacos_mult, ' ', self.sent_preproc)\n",
    "        self.sent_preproc = self.sent_preproc.strip()\n",
    "    \n",
    "    def remove_b_inicial(self):\n",
    "        if self.sent_preproc.startswith('b '):\n",
    "            self.sent_preproc = self.sent_preproc[2:]\n",
    "    \n",
    "    def separa_palavras_coladas(self):\n",
    "        \"\"\"Separa com espaço palavras coladas, aqui definido quando uma letra \n",
    "        minúscula está colada com uma maiúscula imediatalmente posterior\"\"\"\n",
    "        ptn_ltr_minusc_colada_maiuscula = r'([a-z])([A-Z])'\n",
    "        ptn_algarismo_colado_maiuscula = r'([0-9])([A-Z])'\n",
    "        \n",
    "        self.sent_preproc = re.sub(ptn_ltr_minusc_colada_maiuscula, r'\\1 \\2', self.sent_preproc)\n",
    "        self.sent_preproc = re.sub(ptn_algarismo_colado_maiuscula, r'\\1 \\2', self.sent_preproc)\n",
    "    \n",
    "    def preproc(self):\n",
    "        self.sent_preproc = ''\n",
    "        self.remove_caracteres_nao_alfanumericos()\n",
    "        self.remove_espacos_multiplos()\n",
    "        self.remove_b_inicial()\n",
    "        self.separa_palavras_coladas()\n",
    "        self.sent_preproc = self.sent_preproc.lower()\n",
    "        \n",
    "        return self.sent_preproc\n",
    "    \n",
    "    def __getitem__(self, indices):\n",
    "        return ''.join(self.sent_preproc[indices])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.sent_preproc)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.sent_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['opo_texto_preproc'] = X['opo_texto'].apply(Sentenca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skip to content go search royal society org the royal society venue hire contact us fellow login search show navigation home fellows events grants schemes awards topics policy journals collections about us what s new search the fellows directory search for past fellows about elections biographical memoirs'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['opo_texto_preproc'].iloc[0][:306]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opo_texto</th>\n",
       "      <th>opo_texto_preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page biomedical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page collaborati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page doctoral st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page innovator a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page internation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page internation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page internation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page investigato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page joint globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page joint healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page multi user ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            opo_texto  \\\n",
       "0   Skip to contentGo\\n                        Sea...   \n",
       "1   Skip to contentGo\\n                        Sea...   \n",
       "2   Skip to contentGo\\n                        Sea...   \n",
       "3   Skip to contentGo\\n                        Sea...   \n",
       "4   Skip to contentGo\\n                        Sea...   \n",
       "5   Skip to contentGo\\n                        Sea...   \n",
       "6   Skip to contentGo\\n                        Sea...   \n",
       "7   Skip to contentGo\\n                        Sea...   \n",
       "8   Skip to contentGo\\n                        Sea...   \n",
       "9   Grant Funding/Schemes/                        ...   \n",
       "10  Grant Funding/Schemes/                        ...   \n",
       "11  Grant Funding/Schemes/                        ...   \n",
       "12  Grant Funding/Schemes/                        ...   \n",
       "13  Grant Funding/Schemes/                        ...   \n",
       "14  Grant Funding/Schemes/                        ...   \n",
       "15  Grant Funding/Schemes/                        ...   \n",
       "16  Grant Funding/Schemes/                        ...   \n",
       "17  Grant Funding/Schemes/                        ...   \n",
       "18  Grant Funding/Schemes/                        ...   \n",
       "19  Grant Funding/Schemes/                        ...   \n",
       "\n",
       "                                    opo_texto_preproc  \n",
       "0   skip to content go search royal society org th...  \n",
       "1   skip to content go search royal society org th...  \n",
       "2   skip to content go search royal society org th...  \n",
       "3   skip to content go search royal society org th...  \n",
       "4   skip to content go search royal society org th...  \n",
       "5   skip to content go search royal society org th...  \n",
       "6   skip to content go search royal society org th...  \n",
       "7   skip to content go search royal society org th...  \n",
       "8   skip to content go search royal society org th...  \n",
       "9   grant funding schemes current page biomedical ...  \n",
       "10  grant funding schemes current page collaborati...  \n",
       "11  grant funding schemes current page doctoral st...  \n",
       "12  grant funding schemes current page innovator a...  \n",
       "13  grant funding schemes current page internation...  \n",
       "14  grant funding schemes current page internation...  \n",
       "15  grant funding schemes current page internation...  \n",
       "16  grant funding schemes current page investigato...  \n",
       "17  grant funding schemes current page joint globa...  \n",
       "18  grant funding schemes current page joint healt...  \n",
       "19  grant funding schemes current page multi user ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_ingles = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentenca):\n",
    "    tokens = str(sentenca).split(' ')\n",
    "    tokens_sem_stops = [token for token in tokens if token not in stop_ingles]\n",
    "    return ' '.join(tokens_sem_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['opo_texto_sem_stop'] = X['opo_texto_preproc'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opo_texto</th>\n",
       "      <th>opo_texto_preproc</th>\n",
       "      <th>opo_texto_sem_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Skip to contentGo\\n                        Sea...</td>\n",
       "      <td>skip to content go search royal society org th...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page biomedical ...</td>\n",
       "      <td>grant funding schemes current page biomedical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page collaborati...</td>\n",
       "      <td>grant funding schemes current page collaborati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page doctoral st...</td>\n",
       "      <td>grant funding schemes current page doctoral st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page innovator a...</td>\n",
       "      <td>grant funding schemes current page innovator a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page internation...</td>\n",
       "      <td>grant funding schemes current page internation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page internation...</td>\n",
       "      <td>grant funding schemes current page internation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page internation...</td>\n",
       "      <td>grant funding schemes current page internation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page investigato...</td>\n",
       "      <td>grant funding schemes current page investigato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page joint globa...</td>\n",
       "      <td>grant funding schemes current page joint globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page joint healt...</td>\n",
       "      <td>grant funding schemes current page joint healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Grant Funding/Schemes/                        ...</td>\n",
       "      <td>grant funding schemes current page multi user ...</td>\n",
       "      <td>grant funding schemes current page multi user ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            opo_texto  \\\n",
       "0   Skip to contentGo\\n                        Sea...   \n",
       "1   Skip to contentGo\\n                        Sea...   \n",
       "2   Skip to contentGo\\n                        Sea...   \n",
       "3   Skip to contentGo\\n                        Sea...   \n",
       "4   Skip to contentGo\\n                        Sea...   \n",
       "5   Skip to contentGo\\n                        Sea...   \n",
       "6   Skip to contentGo\\n                        Sea...   \n",
       "7   Skip to contentGo\\n                        Sea...   \n",
       "8   Skip to contentGo\\n                        Sea...   \n",
       "9   Grant Funding/Schemes/                        ...   \n",
       "10  Grant Funding/Schemes/                        ...   \n",
       "11  Grant Funding/Schemes/                        ...   \n",
       "12  Grant Funding/Schemes/                        ...   \n",
       "13  Grant Funding/Schemes/                        ...   \n",
       "14  Grant Funding/Schemes/                        ...   \n",
       "15  Grant Funding/Schemes/                        ...   \n",
       "16  Grant Funding/Schemes/                        ...   \n",
       "17  Grant Funding/Schemes/                        ...   \n",
       "18  Grant Funding/Schemes/                        ...   \n",
       "19  Grant Funding/Schemes/                        ...   \n",
       "\n",
       "                                    opo_texto_preproc  \\\n",
       "0   skip to content go search royal society org th...   \n",
       "1   skip to content go search royal society org th...   \n",
       "2   skip to content go search royal society org th...   \n",
       "3   skip to content go search royal society org th...   \n",
       "4   skip to content go search royal society org th...   \n",
       "5   skip to content go search royal society org th...   \n",
       "6   skip to content go search royal society org th...   \n",
       "7   skip to content go search royal society org th...   \n",
       "8   skip to content go search royal society org th...   \n",
       "9   grant funding schemes current page biomedical ...   \n",
       "10  grant funding schemes current page collaborati...   \n",
       "11  grant funding schemes current page doctoral st...   \n",
       "12  grant funding schemes current page innovator a...   \n",
       "13  grant funding schemes current page internation...   \n",
       "14  grant funding schemes current page internation...   \n",
       "15  grant funding schemes current page internation...   \n",
       "16  grant funding schemes current page investigato...   \n",
       "17  grant funding schemes current page joint globa...   \n",
       "18  grant funding schemes current page joint healt...   \n",
       "19  grant funding schemes current page multi user ...   \n",
       "\n",
       "                                   opo_texto_sem_stop  \n",
       "0   skip content go search royal society org royal...  \n",
       "1   skip content go search royal society org royal...  \n",
       "2   skip content go search royal society org royal...  \n",
       "3   skip content go search royal society org royal...  \n",
       "4   skip content go search royal society org royal...  \n",
       "5   skip content go search royal society org royal...  \n",
       "6   skip content go search royal society org royal...  \n",
       "7   skip content go search royal society org royal...  \n",
       "8   skip content go search royal society org royal...  \n",
       "9   grant funding schemes current page biomedical ...  \n",
       "10  grant funding schemes current page collaborati...  \n",
       "11  grant funding schemes current page doctoral st...  \n",
       "12  grant funding schemes current page innovator a...  \n",
       "13  grant funding schemes current page internation...  \n",
       "14  grant funding schemes current page internation...  \n",
       "15  grant funding schemes current page internation...  \n",
       "16  grant funding schemes current page investigato...  \n",
       "17  grant funding schemes current page joint globa...  \n",
       "18  grant funding schemes current page joint healt...  \n",
       "19  grant funding schemes current page multi user ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip content go search royal society org royal society venue hire contact us fellow login search show navigation home fellows events grants schemes awards topics policy journals collections us new search fellows directory search past fellows elections biographical memoirs public events scientific meet \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(X['opo_texto_sem_stop'][0][:302], '\\n...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['opo_texto_tokens'] = X['opo_texto_sem_stop'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skip', 'content', 'go', 'search', 'royal', 'society', 'org', 'royal', 'society', 'venue', 'hire', 'contact', 'us', 'fellow', 'login', 'search', 'show', 'navigation', 'home', 'fellows', 'events', 'grants', 'schemes', 'awards', 'topics', 'policy', 'journals', 'collections', 'us', 'new', 'search', 'fellows', 'directory', 'search', 'past', 'fellows', 'elections', 'biographical', 'memoirs', 'public', 'events', 'scientific', 'meetings', 'summer', 'science', 'online', 'planet', 'grants', 'awards', 'training'] \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(X['opo_texto_tokens'].iloc[0][:50], '\\n...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lematização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematiza_tokens(tokens):\n",
    "    return [wordnet.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lematização dos tokens\n",
    "X['opo_texto_tokens_lem'] = X['opo_texto_tokens'].apply(lematiza_tokens)\n",
    "X['opo_texto_sem_stop_lem'] = X['opo_texto_tokens_lem'].apply(lambda l: ' '.join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenização e Lematização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opo_texto_tokens</th>\n",
       "      <th>opo_texto_tokens_lem</th>\n",
       "      <th>opo_texto_sem_stop_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>skip content go search royal society org royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[grant, funding, schemes, current, page, biome...</td>\n",
       "      <td>[grant, funding, scheme, current, page, biomed...</td>\n",
       "      <td>grant funding scheme current page biomedical r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[grant, funding, schemes, current, page, colla...</td>\n",
       "      <td>[grant, funding, scheme, current, page, collab...</td>\n",
       "      <td>grant funding scheme current page collaborativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[grant, funding, schemes, current, page, docto...</td>\n",
       "      <td>[grant, funding, scheme, current, page, doctor...</td>\n",
       "      <td>grant funding scheme current page doctoral stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[grant, funding, schemes, current, page, innov...</td>\n",
       "      <td>[grant, funding, scheme, current, page, innova...</td>\n",
       "      <td>grant funding scheme current page innovator aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[grant, funding, schemes, current, page, inter...</td>\n",
       "      <td>[grant, funding, scheme, current, page, intern...</td>\n",
       "      <td>grant funding scheme current page internationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[grant, funding, schemes, current, page, inter...</td>\n",
       "      <td>[grant, funding, scheme, current, page, intern...</td>\n",
       "      <td>grant funding scheme current page internationa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     opo_texto_tokens  \\\n",
       "0   [skip, content, go, search, royal, society, or...   \n",
       "1   [skip, content, go, search, royal, society, or...   \n",
       "2   [skip, content, go, search, royal, society, or...   \n",
       "3   [skip, content, go, search, royal, society, or...   \n",
       "4   [skip, content, go, search, royal, society, or...   \n",
       "5   [skip, content, go, search, royal, society, or...   \n",
       "6   [skip, content, go, search, royal, society, or...   \n",
       "7   [skip, content, go, search, royal, society, or...   \n",
       "8   [skip, content, go, search, royal, society, or...   \n",
       "9   [grant, funding, schemes, current, page, biome...   \n",
       "10  [grant, funding, schemes, current, page, colla...   \n",
       "11  [grant, funding, schemes, current, page, docto...   \n",
       "12  [grant, funding, schemes, current, page, innov...   \n",
       "13  [grant, funding, schemes, current, page, inter...   \n",
       "14  [grant, funding, schemes, current, page, inter...   \n",
       "\n",
       "                                 opo_texto_tokens_lem  \\\n",
       "0   [skip, content, go, search, royal, society, or...   \n",
       "1   [skip, content, go, search, royal, society, or...   \n",
       "2   [skip, content, go, search, royal, society, or...   \n",
       "3   [skip, content, go, search, royal, society, or...   \n",
       "4   [skip, content, go, search, royal, society, or...   \n",
       "5   [skip, content, go, search, royal, society, or...   \n",
       "6   [skip, content, go, search, royal, society, or...   \n",
       "7   [skip, content, go, search, royal, society, or...   \n",
       "8   [skip, content, go, search, royal, society, or...   \n",
       "9   [grant, funding, scheme, current, page, biomed...   \n",
       "10  [grant, funding, scheme, current, page, collab...   \n",
       "11  [grant, funding, scheme, current, page, doctor...   \n",
       "12  [grant, funding, scheme, current, page, innova...   \n",
       "13  [grant, funding, scheme, current, page, intern...   \n",
       "14  [grant, funding, scheme, current, page, intern...   \n",
       "\n",
       "                               opo_texto_sem_stop_lem  \n",
       "0   skip content go search royal society org royal...  \n",
       "1   skip content go search royal society org royal...  \n",
       "2   skip content go search royal society org royal...  \n",
       "3   skip content go search royal society org royal...  \n",
       "4   skip content go search royal society org royal...  \n",
       "5   skip content go search royal society org royal...  \n",
       "6   skip content go search royal society org royal...  \n",
       "7   skip content go search royal society org royal...  \n",
       "8   skip content go search royal society org royal...  \n",
       "9   grant funding scheme current page biomedical r...  \n",
       "10  grant funding scheme current page collaborativ...  \n",
       "11  grant funding scheme current page doctoral stu...  \n",
       "12  grant funding scheme current page innovator aw...  \n",
       "13  grant funding scheme current page internationa...  \n",
       "14  grant funding scheme current page internationa...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['opo_texto_tokens', 'opo_texto_tokens_lem', 'opo_texto_sem_stop_lem']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['opo_texto_bow'] = X['opo_texto_tokens'].apply(Counter)\n",
    "X['opo_texto_bow_lem'] = X['opo_texto_tokens_lem'].apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words com e sem lematização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opo_texto_tokens</th>\n",
       "      <th>opo_texto_bow</th>\n",
       "      <th>opo_texto_bow_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 1, 'search': 1...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 1, 'search': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>{'skip': 1, 'content': 4, 'go': 1, 'search': 1...</td>\n",
       "      <td>{'skip': 1, 'content': 4, 'go': 1, 'search': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "      <td>{'skip': 1, 'content': 3, 'go': 2, 'search': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[grant, funding, schemes, current, page, biome...</td>\n",
       "      <td>{'grant': 34, 'funding': 15, 'schemes': 4, 'cu...</td>\n",
       "      <td>{'grant': 47, 'funding': 15, 'scheme': 9, 'cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[grant, funding, schemes, current, page, colla...</td>\n",
       "      <td>{'grant': 28, 'funding': 15, 'schemes': 4, 'cu...</td>\n",
       "      <td>{'grant': 30, 'funding': 15, 'scheme': 11, 'cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[grant, funding, schemes, current, page, docto...</td>\n",
       "      <td>{'grant': 12, 'funding': 11, 'schemes': 5, 'cu...</td>\n",
       "      <td>{'grant': 14, 'funding': 11, 'scheme': 10, 'cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[grant, funding, schemes, current, page, innov...</td>\n",
       "      <td>{'grant': 29, 'funding': 16, 'schemes': 3, 'cu...</td>\n",
       "      <td>{'grant': 30, 'funding': 16, 'scheme': 8, 'cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[grant, funding, schemes, current, page, inter...</td>\n",
       "      <td>{'grant': 24, 'funding': 11, 'schemes': 4, 'cu...</td>\n",
       "      <td>{'grant': 26, 'funding': 11, 'scheme': 12, 'cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[grant, funding, schemes, current, page, inter...</td>\n",
       "      <td>{'grant': 22, 'funding': 10, 'schemes': 5, 'cu...</td>\n",
       "      <td>{'grant': 23, 'funding': 10, 'scheme': 12, 'cu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     opo_texto_tokens  \\\n",
       "0   [skip, content, go, search, royal, society, or...   \n",
       "1   [skip, content, go, search, royal, society, or...   \n",
       "2   [skip, content, go, search, royal, society, or...   \n",
       "3   [skip, content, go, search, royal, society, or...   \n",
       "4   [skip, content, go, search, royal, society, or...   \n",
       "5   [skip, content, go, search, royal, society, or...   \n",
       "6   [skip, content, go, search, royal, society, or...   \n",
       "7   [skip, content, go, search, royal, society, or...   \n",
       "8   [skip, content, go, search, royal, society, or...   \n",
       "9   [grant, funding, schemes, current, page, biome...   \n",
       "10  [grant, funding, schemes, current, page, colla...   \n",
       "11  [grant, funding, schemes, current, page, docto...   \n",
       "12  [grant, funding, schemes, current, page, innov...   \n",
       "13  [grant, funding, schemes, current, page, inter...   \n",
       "14  [grant, funding, schemes, current, page, inter...   \n",
       "\n",
       "                                        opo_texto_bow  \\\n",
       "0   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...   \n",
       "1   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...   \n",
       "2   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...   \n",
       "3   {'skip': 1, 'content': 3, 'go': 1, 'search': 1...   \n",
       "4   {'skip': 1, 'content': 4, 'go': 1, 'search': 1...   \n",
       "5   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...   \n",
       "6   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...   \n",
       "7   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...   \n",
       "8   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...   \n",
       "9   {'grant': 34, 'funding': 15, 'schemes': 4, 'cu...   \n",
       "10  {'grant': 28, 'funding': 15, 'schemes': 4, 'cu...   \n",
       "11  {'grant': 12, 'funding': 11, 'schemes': 5, 'cu...   \n",
       "12  {'grant': 29, 'funding': 16, 'schemes': 3, 'cu...   \n",
       "13  {'grant': 24, 'funding': 11, 'schemes': 4, 'cu...   \n",
       "14  {'grant': 22, 'funding': 10, 'schemes': 5, 'cu...   \n",
       "\n",
       "                                    opo_texto_bow_lem  \n",
       "0   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...  \n",
       "1   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...  \n",
       "2   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...  \n",
       "3   {'skip': 1, 'content': 3, 'go': 1, 'search': 1...  \n",
       "4   {'skip': 1, 'content': 4, 'go': 1, 'search': 1...  \n",
       "5   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...  \n",
       "6   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...  \n",
       "7   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...  \n",
       "8   {'skip': 1, 'content': 3, 'go': 2, 'search': 1...  \n",
       "9   {'grant': 47, 'funding': 15, 'scheme': 9, 'cur...  \n",
       "10  {'grant': 30, 'funding': 15, 'scheme': 11, 'cu...  \n",
       "11  {'grant': 14, 'funding': 11, 'scheme': 10, 'cu...  \n",
       "12  {'grant': 30, 'funding': 16, 'scheme': 8, 'cur...  \n",
       "13  {'grant': 26, 'funding': 11, 'scheme': 12, 'cu...  \n",
       "14  {'grant': 23, 'funding': 10, 'scheme': 12, 'cu...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['opo_texto_tokens', 'opo_texto_bow', 'opo_texto_bow_lem']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapeamento do Corpus em Dicionário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos passar a usar números para representar cada token, por meio da criação de um `dicionario_corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dicionario_corpus = Dictionary(X['opo_texto_tokens'].tolist() + X['opo_texto_tokens_lem'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado do mapeamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dicionario do corpus:\n",
      "\n",
      "{'00': 0, '000': 1, '000â': 2, '1': 3, '10': 4, '100': 5, '17': 6, '173': 7, '19': 8, '1kb': 9, '20': 10, '2017': 11, '2018': 12, '2019â': 13, '2020': 14, '2020â': 15, '2021': 16, '207': 17, '207043': 18, '24': 19, '25': 20, '2500': 21, '2666': 22, '28': 23, '295': 24, '3pm': 25, '44': 26, '451': 27, '5': 28, '6': 29, '7': 30, '7451': 31, '7kb': 32, '8kb': 33, '9': 34, '92': 35, 'academies': 36, 'academiesâ': 37, 'academy': 38, 'access': 39, 'across': 40, 'activities': 41, 'addition': 42, 'adjustment': 43, 'administrative': 44, 'advancing': 45, 'ag': 46, 'also': 47, 'apex': 48, 'applicant': 49, 'applicants': 50, 'application': 51, 'applications': 52, 'apply': 53, 'applying': 54, 'area': 55, 'around': 56, 'articles': 57, 'authors': 58, 'available': 59, 'award': 60, 'awards': 61, 'bank': 62, 'based': 63, 'benefit': 64, 'biographical': 65, 'blog': 66, 'book': 67, 'boundary': 68, 'brexit': 69, 'british': 70, 'browser': 71, 'call': 72, 'carlton': 73, 'catalogues': 74, 'charity': 75, 'close': 76, 'closed': 77, 'co': 78, 'collaborate': 79}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print('Dicionario do corpus:\\n\\n',\n",
    "      {k: v for i, (k, v) in enumerate(dicionario_corpus.token2id.items()) if i < 80}, '\\n...', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de consulta ao dicionário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicionario_corpus.token2id['grant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grant'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicionario_corpus.get(156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words com Dicionário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar duas novas colunas fazendo `bag of words` de pares de inteiros para o texto normal e para o lematizado.\n",
    "O primeiro elemento deste par é o `id` do token no `dicionario_corpus` e o segundo elemento é a contagem de ocorrências deste token no documento.\n",
    "\n",
    "Estamos convencionando chamar as colunas inteiras de `'opo_int_...'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação dos bag of words para o texto normal e lematizado\n",
    "X['opo_int_bow'] = X['opo_texto_tokens'].apply(dicionario_corpus.doc2bow)\n",
    "X['opo_int_bow_lem'] = X['opo_texto_tokens_lem'].apply(dicionario_corpus.doc2bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado dos bag of words após mapeamento em dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opo_texto_tokens</th>\n",
       "      <th>opo_int_bow</th>\n",
       "      <th>opo_int_bow_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[(0, 2), (1, 1), (2, 1), (3, 3), (4, 1), (5, 1...</td>\n",
       "      <td>[(0, 2), (1, 1), (2, 1), (3, 3), (4, 1), (5, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[(0, 2), (1, 3), (4, 1), (6, 1), (8, 2), (10, ...</td>\n",
       "      <td>[(0, 2), (1, 3), (4, 1), (6, 1), (8, 2), (10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[(0, 2), (1, 5), (4, 2), (6, 1), (8, 2), (10, ...</td>\n",
       "      <td>[(0, 2), (1, 5), (4, 2), (6, 1), (8, 2), (10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[(0, 2), (1, 2), (3, 1), (4, 1), (6, 1), (8, 2...</td>\n",
       "      <td>[(0, 2), (1, 2), (3, 1), (4, 1), (6, 1), (8, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[(0, 2), (1, 2), (3, 3), (6, 2), (8, 3), (14, ...</td>\n",
       "      <td>[(0, 2), (1, 2), (3, 3), (6, 2), (8, 3), (14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[(0, 2), (1, 1), (4, 1), (6, 2), (8, 3), (10, ...</td>\n",
       "      <td>[(0, 2), (1, 1), (4, 1), (6, 2), (8, 3), (10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[(0, 2), (1, 3), (4, 1), (6, 2), (8, 3), (10, ...</td>\n",
       "      <td>[(0, 2), (1, 3), (4, 1), (6, 2), (8, 3), (10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[(0, 2), (1, 1), (3, 2), (6, 1), (8, 2), (10, ...</td>\n",
       "      <td>[(0, 2), (1, 1), (3, 2), (6, 1), (8, 2), (10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[skip, content, go, search, royal, society, or...</td>\n",
       "      <td>[(0, 2), (1, 3), (6, 1), (8, 2), (9, 1), (10, ...</td>\n",
       "      <td>[(0, 2), (1, 3), (6, 1), (8, 2), (9, 1), (10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[grant, funding, schemes, current, page, biome...</td>\n",
       "      <td>[(0, 3), (1, 5), (3, 11), (4, 3), (5, 3), (6, ...</td>\n",
       "      <td>[(0, 3), (1, 5), (3, 11), (4, 3), (5, 3), (6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[grant, funding, schemes, current, page, colla...</td>\n",
       "      <td>[(0, 1), (1, 5), (3, 9), (4, 3), (5, 3), (6, 1...</td>\n",
       "      <td>[(0, 1), (1, 5), (3, 9), (4, 3), (5, 3), (6, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[grant, funding, schemes, current, page, docto...</td>\n",
       "      <td>[(0, 2), (1, 3), (3, 9), (4, 2), (5, 2), (6, 2...</td>\n",
       "      <td>[(0, 2), (1, 3), (3, 9), (4, 2), (5, 2), (6, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[grant, funding, schemes, current, page, innov...</td>\n",
       "      <td>[(0, 1), (1, 9), (3, 10), (4, 2), (5, 2), (6, ...</td>\n",
       "      <td>[(0, 1), (1, 9), (3, 10), (4, 2), (5, 2), (6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[grant, funding, schemes, current, page, inter...</td>\n",
       "      <td>[(1, 8), (3, 10), (4, 2), (5, 3), (10, 1), (16...</td>\n",
       "      <td>[(1, 8), (3, 10), (4, 2), (5, 3), (10, 1), (16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[grant, funding, schemes, current, page, inter...</td>\n",
       "      <td>[(0, 4), (1, 6), (3, 5), (4, 2), (6, 4), (8, 1...</td>\n",
       "      <td>[(0, 4), (1, 6), (3, 5), (4, 2), (6, 4), (8, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     opo_texto_tokens  \\\n",
       "0   [skip, content, go, search, royal, society, or...   \n",
       "1   [skip, content, go, search, royal, society, or...   \n",
       "2   [skip, content, go, search, royal, society, or...   \n",
       "3   [skip, content, go, search, royal, society, or...   \n",
       "4   [skip, content, go, search, royal, society, or...   \n",
       "5   [skip, content, go, search, royal, society, or...   \n",
       "6   [skip, content, go, search, royal, society, or...   \n",
       "7   [skip, content, go, search, royal, society, or...   \n",
       "8   [skip, content, go, search, royal, society, or...   \n",
       "9   [grant, funding, schemes, current, page, biome...   \n",
       "10  [grant, funding, schemes, current, page, colla...   \n",
       "11  [grant, funding, schemes, current, page, docto...   \n",
       "12  [grant, funding, schemes, current, page, innov...   \n",
       "13  [grant, funding, schemes, current, page, inter...   \n",
       "14  [grant, funding, schemes, current, page, inter...   \n",
       "\n",
       "                                          opo_int_bow  \\\n",
       "0   [(0, 2), (1, 1), (2, 1), (3, 3), (4, 1), (5, 1...   \n",
       "1   [(0, 2), (1, 3), (4, 1), (6, 1), (8, 2), (10, ...   \n",
       "2   [(0, 2), (1, 5), (4, 2), (6, 1), (8, 2), (10, ...   \n",
       "3   [(0, 2), (1, 2), (3, 1), (4, 1), (6, 1), (8, 2...   \n",
       "4   [(0, 2), (1, 2), (3, 3), (6, 2), (8, 3), (14, ...   \n",
       "5   [(0, 2), (1, 1), (4, 1), (6, 2), (8, 3), (10, ...   \n",
       "6   [(0, 2), (1, 3), (4, 1), (6, 2), (8, 3), (10, ...   \n",
       "7   [(0, 2), (1, 1), (3, 2), (6, 1), (8, 2), (10, ...   \n",
       "8   [(0, 2), (1, 3), (6, 1), (8, 2), (9, 1), (10, ...   \n",
       "9   [(0, 3), (1, 5), (3, 11), (4, 3), (5, 3), (6, ...   \n",
       "10  [(0, 1), (1, 5), (3, 9), (4, 3), (5, 3), (6, 1...   \n",
       "11  [(0, 2), (1, 3), (3, 9), (4, 2), (5, 2), (6, 2...   \n",
       "12  [(0, 1), (1, 9), (3, 10), (4, 2), (5, 2), (6, ...   \n",
       "13  [(1, 8), (3, 10), (4, 2), (5, 3), (10, 1), (16...   \n",
       "14  [(0, 4), (1, 6), (3, 5), (4, 2), (6, 4), (8, 1...   \n",
       "\n",
       "                                      opo_int_bow_lem  \n",
       "0   [(0, 2), (1, 1), (2, 1), (3, 3), (4, 1), (5, 1...  \n",
       "1   [(0, 2), (1, 3), (4, 1), (6, 1), (8, 2), (10, ...  \n",
       "2   [(0, 2), (1, 5), (4, 2), (6, 1), (8, 2), (10, ...  \n",
       "3   [(0, 2), (1, 2), (3, 1), (4, 1), (6, 1), (8, 2...  \n",
       "4   [(0, 2), (1, 2), (3, 3), (6, 2), (8, 3), (14, ...  \n",
       "5   [(0, 2), (1, 1), (4, 1), (6, 2), (8, 3), (10, ...  \n",
       "6   [(0, 2), (1, 3), (4, 1), (6, 2), (8, 3), (10, ...  \n",
       "7   [(0, 2), (1, 1), (3, 2), (6, 1), (8, 2), (10, ...  \n",
       "8   [(0, 2), (1, 3), (6, 1), (8, 2), (9, 1), (10, ...  \n",
       "9   [(0, 3), (1, 5), (3, 11), (4, 3), (5, 3), (6, ...  \n",
       "10  [(0, 1), (1, 5), (3, 9), (4, 3), (5, 3), (6, 1...  \n",
       "11  [(0, 2), (1, 3), (3, 9), (4, 2), (5, 2), (6, 2...  \n",
       "12  [(0, 1), (1, 9), (3, 10), (4, 2), (5, 2), (6, ...  \n",
       "13  [(1, 8), (3, 10), (4, 2), (5, 3), (10, 1), (16...  \n",
       "14  [(0, 4), (1, 6), (3, 5), (4, 2), (6, 4), (8, 1...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['opo_texto_tokens', 'opo_int_bow', 'opo_int_bow_lem']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfdif_palavras_mais_representativas(col_tfidf, dicionario, top=5):\n",
    "    palavras_mais_repr = []\n",
    "    for idx, tfidf_doc in enumerate(col_tfidf):\n",
    "        palavras =[]\n",
    "        # lista ordenada pelo peso tfidf do termo\n",
    "        tfidf_desc = sorted(tfidf_doc, key=lambda termo: termo[1], reverse=True)\n",
    "\n",
    "        # lista no tamanho especificado\n",
    "        tfidf_desc_tam = tfidf_desc[:top]\n",
    "\n",
    "        # conversão dos tokenids para palavras\n",
    "        palavras = [(dicionario.get(tokenid), peso) for tokenid, peso in tfidf_desc_tam]\n",
    "        palavras_mais_repr.append({f'Palavra_Rank_{rank + 1}': palavras[rank] for rank in range(len(palavras))})\n",
    "\n",
    "    return pd.DataFrame(palavras_mais_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_tfidf_mais_representativos(serie_int_bow, tam=10):\n",
    "    \"\"\"Gera um dataframe com os dados de tfidf\n",
    "    para os `tam` tokens mais representativos de cada documento\"\"\"\n",
    "    \n",
    "    corpus = serie_int_bow.to_list()\n",
    "    tfidf = TfidfModel(corpus=corpus)\n",
    "    \n",
    "    tfidf_docs = []\n",
    "    for idx, doc in enumerate(corpus):\n",
    "        tfidf_doc = tfidf[doc]\n",
    "    \n",
    "        # lista ordenada pelo peso tfidf do termo\n",
    "        tfidf_desc = sorted(tfidf_doc, key=lambda termo: termo[1], reverse=True)\n",
    "\n",
    "        # lista no tamanho especificado\n",
    "        tfidf_desc_tam = tfidf_desc[:tam]\n",
    "\n",
    "        tfidf_docs.append({f'tdidf_desc_tam_{tam}': tfidf_desc_tam})\n",
    "        \n",
    "    return pd.DataFrame(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera colunas com os tfidfs para cada documento\n",
    "X['opo_int_tfidf'] = gera_tfidf_mais_representativos(X['opo_int_bow'], tam=30)\n",
    "X['opo_int_tfidf_lem'] = gera_tfidf_mais_representativos(X['opo_int_bow_lem'], tam=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado do TF-IDF para o corpus normal e o lematizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opo_int_tfidf</th>\n",
       "      <th>opo_int_tfidf_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(48, 0.5852419808628487), (305, 0.25482896958...</td>\n",
       "      <td>[(48, 0.5912011244922791), (305, 0.25742372949...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(111, 0.30992399496115636), (451, 0.290495776...</td>\n",
       "      <td>[(111, 0.31345516543738), (451, 0.293805588120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(672, 0.44624227693180224), (741, 0.313404622...</td>\n",
       "      <td>[(3542, 0.45343844147211687), (741, 0.31845862...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(707, 0.49824169968051996), (305, 0.263958904...</td>\n",
       "      <td>[(707, 0.5070887386855577), (305, 0.2686458962...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(967, 0.39799465030110376), (978, 0.364828429...</td>\n",
       "      <td>[(967, 0.40518569321509584), (978, 0.371420218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[(1151, 0.39683650979336466), (293, 0.32923078...</td>\n",
       "      <td>[(1151, 0.3987789857858959), (293, 0.330842339...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[(1148, 0.4264028136991138), (1151, 0.31011113...</td>\n",
       "      <td>[(1148, 0.43081297567455795), (1151, 0.3133185...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[(176, 0.3434791064044698), (305, 0.2685837163...</td>\n",
       "      <td>[(176, 0.3529012393206013), (305, 0.2759513594...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[(111, 0.4291669460596476), (1351, 0.209297274...</td>\n",
       "      <td>[(111, 0.43415835184452745), (1351, 0.21173149...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[(91, 0.42298451835661083), (1785, 0.330111397...</td>\n",
       "      <td>[(658, 0.474333701515959), (1415, 0.2432449240...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[(91, 0.45171540992354864), (1415, 0.250983141...</td>\n",
       "      <td>[(658, 0.47868312316678613), (1415, 0.24547536...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[(91, 0.3322647155166575), (1005, 0.1901806407...</td>\n",
       "      <td>[(658, 0.3771962200292913), (2070, 0.179831200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[(91, 0.41610270332150784), (2206, 0.286769569...</td>\n",
       "      <td>[(658, 0.43772444685001927), (2206, 0.28353714...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[(91, 0.44427287853629777), (1415, 0.242400195...</td>\n",
       "      <td>[(658, 0.4724462536473686), (1415, 0.236642665...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[(91, 0.3362616302571846), (2356, 0.2242353123...</td>\n",
       "      <td>[(658, 0.36663264906159965), (2356, 0.22358118...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        opo_int_tfidf  \\\n",
       "0   [(48, 0.5852419808628487), (305, 0.25482896958...   \n",
       "1   [(111, 0.30992399496115636), (451, 0.290495776...   \n",
       "2   [(672, 0.44624227693180224), (741, 0.313404622...   \n",
       "3   [(707, 0.49824169968051996), (305, 0.263958904...   \n",
       "4   [(967, 0.39799465030110376), (978, 0.364828429...   \n",
       "5   [(1151, 0.39683650979336466), (293, 0.32923078...   \n",
       "6   [(1148, 0.4264028136991138), (1151, 0.31011113...   \n",
       "7   [(176, 0.3434791064044698), (305, 0.2685837163...   \n",
       "8   [(111, 0.4291669460596476), (1351, 0.209297274...   \n",
       "9   [(91, 0.42298451835661083), (1785, 0.330111397...   \n",
       "10  [(91, 0.45171540992354864), (1415, 0.250983141...   \n",
       "11  [(91, 0.3322647155166575), (1005, 0.1901806407...   \n",
       "12  [(91, 0.41610270332150784), (2206, 0.286769569...   \n",
       "13  [(91, 0.44427287853629777), (1415, 0.242400195...   \n",
       "14  [(91, 0.3362616302571846), (2356, 0.2242353123...   \n",
       "\n",
       "                                    opo_int_tfidf_lem  \n",
       "0   [(48, 0.5912011244922791), (305, 0.25742372949...  \n",
       "1   [(111, 0.31345516543738), (451, 0.293805588120...  \n",
       "2   [(3542, 0.45343844147211687), (741, 0.31845862...  \n",
       "3   [(707, 0.5070887386855577), (305, 0.2686458962...  \n",
       "4   [(967, 0.40518569321509584), (978, 0.371420218...  \n",
       "5   [(1151, 0.3987789857858959), (293, 0.330842339...  \n",
       "6   [(1148, 0.43081297567455795), (1151, 0.3133185...  \n",
       "7   [(176, 0.3529012393206013), (305, 0.2759513594...  \n",
       "8   [(111, 0.43415835184452745), (1351, 0.21173149...  \n",
       "9   [(658, 0.474333701515959), (1415, 0.2432449240...  \n",
       "10  [(658, 0.47868312316678613), (1415, 0.24547536...  \n",
       "11  [(658, 0.3771962200292913), (2070, 0.179831200...  \n",
       "12  [(658, 0.43772444685001927), (2206, 0.28353714...  \n",
       "13  [(658, 0.4724462536473686), (1415, 0.236642665...  \n",
       "14  [(658, 0.36663264906159965), (2356, 0.22358118...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['opo_int_tfidf', 'opo_int_tfidf_lem']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checando as palavras mais importantes por documento, segundo seu TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavra_Rank_1</th>\n",
       "      <th>Palavra_Rank_2</th>\n",
       "      <th>Palavra_Rank_3</th>\n",
       "      <th>Palavra_Rank_4</th>\n",
       "      <th>Palavra_Rank_5</th>\n",
       "      <th>Palavra_Rank_6</th>\n",
       "      <th>Palavra_Rank_7</th>\n",
       "      <th>Palavra_Rank_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(apex, 0.5912011244922791)</td>\n",
       "      <td>(search, 0.2574237294995361)</td>\n",
       "      <td>(academy, 0.15362999079765494)</td>\n",
       "      <td>(journal, 0.15362999079765494)</td>\n",
       "      <td>(fellow, 0.1521140219769986)</td>\n",
       "      <td>(royal, 0.14659138810582206)</td>\n",
       "      <td>(society, 0.12110351111147696)</td>\n",
       "      <td>(topic, 0.10973570771261065)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(dr, 0.31345516543738)</td>\n",
       "      <td>(dorothy, 0.29380558812023994)</td>\n",
       "      <td>(hodgkin, 0.29380558812023994)</td>\n",
       "      <td>(search, 0.21402228419340266)</td>\n",
       "      <td>(fellow, 0.18483742725793864)</td>\n",
       "      <td>(society, 0.15822015173492798)</td>\n",
       "      <td>(royal, 0.15234523924078536)</td>\n",
       "      <td>(journal, 0.1277280910157305)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(exchange, 0.45343844147211687)</td>\n",
       "      <td>(professor, 0.31845862877311487)</td>\n",
       "      <td>(dr, 0.28916657997233086)</td>\n",
       "      <td>(search, 0.19743841793679445)</td>\n",
       "      <td>(society, 0.17249842391877052)</td>\n",
       "      <td>(royal, 0.16864862346047407)</td>\n",
       "      <td>(case, 0.12564262959614192)</td>\n",
       "      <td>(journal, 0.11783087126312472)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(jsps, 0.5070887386855577)</td>\n",
       "      <td>(search, 0.26864589629822416)</td>\n",
       "      <td>(royal, 0.19122739249724244)</td>\n",
       "      <td>(society, 0.18054702122369418)</td>\n",
       "      <td>(japanese, 0.16826564473063313)</td>\n",
       "      <td>(journal, 0.16032735853979738)</td>\n",
       "      <td>(fellow, 0.15874530235804155)</td>\n",
       "      <td>(japan, 0.13829692873242483)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(jardine, 0.40518569321509584)</td>\n",
       "      <td>(lisa, 0.3714202187805045)</td>\n",
       "      <td>(royal, 0.20721503591322246)</td>\n",
       "      <td>(history, 0.1930351023683044)</td>\n",
       "      <td>(search, 0.1617256361143132)</td>\n",
       "      <td>(society, 0.14129680347170512)</td>\n",
       "      <td>(scholar, 0.13875861049867255)</td>\n",
       "      <td>(incorporate, 0.13506189773836527)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(wolfson, 0.3987789857858959)</td>\n",
       "      <td>(royal, 0.33084233901711774)</td>\n",
       "      <td>(society, 0.29816586385539845)</td>\n",
       "      <td>(professor, 0.28396748938609373)</td>\n",
       "      <td>(search, 0.21126546477653016)</td>\n",
       "      <td>(institution, 0.16432690244618936)</td>\n",
       "      <td>(nomination, 0.1450105402857803)</td>\n",
       "      <td>(fellow, 0.14404463507490692)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(visiting, 0.43081297567455795)</td>\n",
       "      <td>(wolfson, 0.31331852776331487)</td>\n",
       "      <td>(royal, 0.3086800156338849)</td>\n",
       "      <td>(society, 0.27610078542765837)</td>\n",
       "      <td>(search, 0.2282364587448744)</td>\n",
       "      <td>(nomination, 0.15665926388165743)</td>\n",
       "      <td>(fellow, 0.1556157673260507)</td>\n",
       "      <td>(journal, 0.13621108327827092)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(industry, 0.3529012393206013)</td>\n",
       "      <td>(search, 0.2759513594512431)</td>\n",
       "      <td>(royal, 0.2749985892637328)</td>\n",
       "      <td>(society, 0.22254810501736386)</td>\n",
       "      <td>(fellow, 0.175605410559882)</td>\n",
       "      <td>(academia, 0.16540057591457386)</td>\n",
       "      <td>(journal, 0.16468724501628063)</td>\n",
       "      <td>(company, 0.12405043193593038)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(dr, 0.43415835184452745)</td>\n",
       "      <td>(urf, 0.21173149681947764)</td>\n",
       "      <td>(search, 0.2028249955432925)</td>\n",
       "      <td>(fellow, 0.17516704160557078)</td>\n",
       "      <td>(society, 0.14994233750676442)</td>\n",
       "      <td>(royal, 0.1443747906275575)</td>\n",
       "      <td>(professor, 0.13631121591524037)</td>\n",
       "      <td>(university, 0.13179969958907617)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(cost, 0.474333701515959)</td>\n",
       "      <td>(ask, 0.24324492405523657)</td>\n",
       "      <td>(allowance, 0.17249939047293733)</td>\n",
       "      <td>(pay, 0.1628463457382818)</td>\n",
       "      <td>(youâ, 0.14594695443314196)</td>\n",
       "      <td>(cover, 0.1434372194865877)</td>\n",
       "      <td>(equipment, 0.13986583133176103)</td>\n",
       "      <td>(away, 0.1359361711188955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(cost, 0.47868312316678613)</td>\n",
       "      <td>(ask, 0.24547536801432776)</td>\n",
       "      <td>(allowance, 0.1740811304616407)</td>\n",
       "      <td>(pay, 0.16433957175121003)</td>\n",
       "      <td>(youâ, 0.14728522080859666)</td>\n",
       "      <td>(cover, 0.14475247274811123)</td>\n",
       "      <td>(organisation, 0.13887368564620983)</td>\n",
       "      <td>(away, 0.13718264322050974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(cost, 0.3771962200292913)</td>\n",
       "      <td>(fee, 0.1798312005867474)</td>\n",
       "      <td>(supervisor, 0.17898580813850248)</td>\n",
       "      <td>(ask, 0.17712474866727268)</td>\n",
       "      <td>(pay, 0.17708029525102148)</td>\n",
       "      <td>(allowance, 0.17585351810331679)</td>\n",
       "      <td>(away, 0.1583764034558559)</td>\n",
       "      <td>(organisation, 0.14607726011422006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(cost, 0.43772444685001927)</td>\n",
       "      <td>(innovator, 0.2835371498045995)</td>\n",
       "      <td>(ask, 0.2076358495697216)</td>\n",
       "      <td>(allowance, 0.15255307961589898)</td>\n",
       "      <td>(organisation, 0.14956707625314272)</td>\n",
       "      <td>(multidisciplinary, 0.1482970137843971)</td>\n",
       "      <td>(pay, 0.14526854301648964)</td>\n",
       "      <td>(youâ, 0.1290709335163134)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(cost, 0.4724462536473686)</td>\n",
       "      <td>(ask, 0.2366426653433204)</td>\n",
       "      <td>(allowance, 0.18879450476276932)</td>\n",
       "      <td>(pay, 0.18483068326174787)</td>\n",
       "      <td>(youâ, 0.14790166583957526)</td>\n",
       "      <td>(organisation, 0.14577688179080955)</td>\n",
       "      <td>(away, 0.14051194119887797)</td>\n",
       "      <td>(income, 0.13764812545262928)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(cost, 0.36663264906159965)</td>\n",
       "      <td>(taught, 0.2235811806384883)</td>\n",
       "      <td>(master, 0.1809740509068137)</td>\n",
       "      <td>(cover, 0.17818186266821975)</td>\n",
       "      <td>(use, 0.1737017757189781)</td>\n",
       "      <td>(course, 0.16776030462950886)</td>\n",
       "      <td>(organisation, 0.16593101923014053)</td>\n",
       "      <td>(supervisor, 0.1554462017944844)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Palavra_Rank_1                    Palavra_Rank_2  \\\n",
       "0        (apex, 0.5912011244922791)      (search, 0.2574237294995361)   \n",
       "1            (dr, 0.31345516543738)    (dorothy, 0.29380558812023994)   \n",
       "2   (exchange, 0.45343844147211687)  (professor, 0.31845862877311487)   \n",
       "3        (jsps, 0.5070887386855577)     (search, 0.26864589629822416)   \n",
       "4    (jardine, 0.40518569321509584)        (lisa, 0.3714202187805045)   \n",
       "5     (wolfson, 0.3987789857858959)      (royal, 0.33084233901711774)   \n",
       "6   (visiting, 0.43081297567455795)    (wolfson, 0.31331852776331487)   \n",
       "7    (industry, 0.3529012393206013)      (search, 0.2759513594512431)   \n",
       "8         (dr, 0.43415835184452745)        (urf, 0.21173149681947764)   \n",
       "9         (cost, 0.474333701515959)        (ask, 0.24324492405523657)   \n",
       "10      (cost, 0.47868312316678613)        (ask, 0.24547536801432776)   \n",
       "11       (cost, 0.3771962200292913)         (fee, 0.1798312005867474)   \n",
       "12      (cost, 0.43772444685001927)   (innovator, 0.2835371498045995)   \n",
       "13       (cost, 0.4724462536473686)         (ask, 0.2366426653433204)   \n",
       "14      (cost, 0.36663264906159965)      (taught, 0.2235811806384883)   \n",
       "\n",
       "                       Palavra_Rank_3                    Palavra_Rank_4  \\\n",
       "0      (academy, 0.15362999079765494)    (journal, 0.15362999079765494)   \n",
       "1      (hodgkin, 0.29380558812023994)     (search, 0.21402228419340266)   \n",
       "2           (dr, 0.28916657997233086)     (search, 0.19743841793679445)   \n",
       "3        (royal, 0.19122739249724244)    (society, 0.18054702122369418)   \n",
       "4        (royal, 0.20721503591322246)     (history, 0.1930351023683044)   \n",
       "5      (society, 0.29816586385539845)  (professor, 0.28396748938609373)   \n",
       "6         (royal, 0.3086800156338849)    (society, 0.27610078542765837)   \n",
       "7         (royal, 0.2749985892637328)    (society, 0.22254810501736386)   \n",
       "8        (search, 0.2028249955432925)     (fellow, 0.17516704160557078)   \n",
       "9    (allowance, 0.17249939047293733)         (pay, 0.1628463457382818)   \n",
       "10    (allowance, 0.1740811304616407)        (pay, 0.16433957175121003)   \n",
       "11  (supervisor, 0.17898580813850248)        (ask, 0.17712474866727268)   \n",
       "12          (ask, 0.2076358495697216)  (allowance, 0.15255307961589898)   \n",
       "13   (allowance, 0.18879450476276932)        (pay, 0.18483068326174787)   \n",
       "14       (master, 0.1809740509068137)      (cover, 0.17818186266821975)   \n",
       "\n",
       "                         Palavra_Rank_5  \\\n",
       "0          (fellow, 0.1521140219769986)   \n",
       "1         (fellow, 0.18483742725793864)   \n",
       "2        (society, 0.17249842391877052)   \n",
       "3       (japanese, 0.16826564473063313)   \n",
       "4          (search, 0.1617256361143132)   \n",
       "5         (search, 0.21126546477653016)   \n",
       "6          (search, 0.2282364587448744)   \n",
       "7           (fellow, 0.175605410559882)   \n",
       "8        (society, 0.14994233750676442)   \n",
       "9           (youâ, 0.14594695443314196)   \n",
       "10          (youâ, 0.14728522080859666)   \n",
       "11           (pay, 0.17708029525102148)   \n",
       "12  (organisation, 0.14956707625314272)   \n",
       "13          (youâ, 0.14790166583957526)   \n",
       "14            (use, 0.1737017757189781)   \n",
       "\n",
       "                             Palavra_Rank_6  \\\n",
       "0              (royal, 0.14659138810582206)   \n",
       "1            (society, 0.15822015173492798)   \n",
       "2              (royal, 0.16864862346047407)   \n",
       "3            (journal, 0.16032735853979738)   \n",
       "4            (society, 0.14129680347170512)   \n",
       "5        (institution, 0.16432690244618936)   \n",
       "6         (nomination, 0.15665926388165743)   \n",
       "7           (academia, 0.16540057591457386)   \n",
       "8               (royal, 0.1443747906275575)   \n",
       "9               (cover, 0.1434372194865877)   \n",
       "10             (cover, 0.14475247274811123)   \n",
       "11         (allowance, 0.17585351810331679)   \n",
       "12  (multidisciplinary, 0.1482970137843971)   \n",
       "13      (organisation, 0.14577688179080955)   \n",
       "14            (course, 0.16776030462950886)   \n",
       "\n",
       "                         Palavra_Rank_7                       Palavra_Rank_8  \n",
       "0        (society, 0.12110351111147696)         (topic, 0.10973570771261065)  \n",
       "1          (royal, 0.15234523924078536)        (journal, 0.1277280910157305)  \n",
       "2           (case, 0.12564262959614192)       (journal, 0.11783087126312472)  \n",
       "3         (fellow, 0.15874530235804155)         (japan, 0.13829692873242483)  \n",
       "4        (scholar, 0.13875861049867255)   (incorporate, 0.13506189773836527)  \n",
       "5      (nomination, 0.1450105402857803)        (fellow, 0.14404463507490692)  \n",
       "6          (fellow, 0.1556157673260507)       (journal, 0.13621108327827092)  \n",
       "7        (journal, 0.16468724501628063)       (company, 0.12405043193593038)  \n",
       "8      (professor, 0.13631121591524037)    (university, 0.13179969958907617)  \n",
       "9      (equipment, 0.13986583133176103)           (away, 0.1359361711188955)  \n",
       "10  (organisation, 0.13887368564620983)          (away, 0.13718264322050974)  \n",
       "11           (away, 0.1583764034558559)  (organisation, 0.14607726011422006)  \n",
       "12           (pay, 0.14526854301648964)           (youâ, 0.1290709335163134)  \n",
       "13          (away, 0.14051194119887797)        (income, 0.13764812545262928)  \n",
       "14  (organisation, 0.16593101923014053)     (supervisor, 0.1554462017944844)  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdif_palavras_mais_representativas(X['opo_int_tfidf_lem'], dicionario_corpus, top=8).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjuntos de Treinamento e de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X['opo_texto_sem_stop'], y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '000â', '01', '03', '06', '09', '10', '100', '102', '11', '115', '12', '120', '123', '125', '127', '128', '13', '131', '137', '139', '14', '140', '148', '15', '150', '153', '16', '165', '17', '173', '17th', '18', '180', '1860', '19', '1kb', '20', '200', '2011', '2014', '2017', '2018', '2019', '2019â', '2020', '2020â', '2021', '20211']\n",
      "[[0.         0.03022061 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.02949415 0.01382312 0.03862879 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00935863 0.01754457 0.         ... 0.         0.         0.        ]\n",
      " [0.00461674 0.02163742 0.         ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000â</th>\n",
       "      <th>01</th>\n",
       "      <th>03</th>\n",
       "      <th>06</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>102</th>\n",
       "      <th>...</th>\n",
       "      <th>youwork</th>\n",
       "      <th>youyour</th>\n",
       "      <th>youâ</th>\n",
       "      <th>yusuf</th>\n",
       "      <th>zhang</th>\n",
       "      <th>zinke</th>\n",
       "      <th>zita</th>\n",
       "      <th>zoology</th>\n",
       "      <th>œgrant</th>\n",
       "      <th>œsupport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010937</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029494</td>\n",
       "      <td>0.013823</td>\n",
       "      <td>0.038629</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.017509</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029480</td>\n",
       "      <td>0.027633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03861</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.022019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.022786</td>\n",
       "      <td>0.032038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029843</td>\n",
       "      <td>0.029843</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.033899</td>\n",
       "      <td>0.018157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.013419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.019142</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02507</td>\n",
       "      <td>0.02507</td>\n",
       "      <td>0.02507</td>\n",
       "      <td>0.02507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.009359</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.012966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.021637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>0.019188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.023454</td>\n",
       "      <td>0.010992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.013923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.024759</td>\n",
       "      <td>0.034811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.052486</td>\n",
       "      <td>0.024599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.032552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.023514</td>\n",
       "      <td>0.033061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.022305</td>\n",
       "      <td>0.052268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.026482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058425</td>\n",
       "      <td>0.029212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.028476</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.033106</td>\n",
       "      <td>0.062064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.026204</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.038926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>0.135763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.025601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.027986</td>\n",
       "      <td>0.021861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.012924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.023647</td>\n",
       "      <td>0.033249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.075765</td>\n",
       "      <td>0.017754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 2959 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          00       000      000â       01       03       06       09  \\\n",
       "0   0.000000  0.030221  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "1   0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "2   0.029494  0.013823  0.038629  0.00000  0.00000  0.00000  0.00000   \n",
       "3   0.029480  0.027633  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "4   0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "5   0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "6   0.022019  0.000000  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "7   0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "8   0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "9   0.022786  0.032038  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "10  0.033899  0.018157  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "11  0.019142  0.017943  0.000000  0.02507  0.02507  0.02507  0.02507   \n",
       "12  0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "13  0.009359  0.017545  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "14  0.004617  0.021637  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "15  0.023454  0.010992  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "16  0.024759  0.034811  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "17  0.052486  0.024599  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "18  0.000000  0.051588  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "19  0.000000  0.046595  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "20  0.023514  0.033061  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "21  0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "22  0.022305  0.052268  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "23  0.028476  0.022244  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "24  0.033106  0.062064  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "25  0.004614  0.038926  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "26  0.004552  0.025601  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "27  0.027986  0.021861  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "28  0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "29  0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "30  0.023647  0.033249  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "31  0.075765  0.017754  0.000000  0.00000  0.00000  0.00000  0.00000   \n",
       "\n",
       "          10       100       102  ...   youwork   youyour      youâ     yusuf  \\\n",
       "0   0.010937  0.019143  0.000000  ...  0.000000  0.000000  0.153191  0.000000   \n",
       "1   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.017509  0.020431  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.017500  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.028168  0.000000   \n",
       "7   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.011500  0.013419  0.000000  ...  0.000000  0.000000  0.123902  0.000000   \n",
       "11  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "13  0.016667  0.012966  0.000000  ...  0.000000  0.000000  0.137678  0.000000   \n",
       "14  0.016444  0.019188  0.000000  ...  0.000000  0.000000  0.141743  0.000000   \n",
       "15  0.013923  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "16  0.014698  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.184644  0.000000   \n",
       "18  0.000000  0.038124  0.000000  ...  0.000000  0.000000  0.035202  0.000000   \n",
       "19  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "20  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.015040  0.000000   \n",
       "21  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "22  0.026482  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.058425   \n",
       "23  0.011270  0.013151  0.000000  ...  0.012432  0.000000  0.133571  0.000000   \n",
       "24  0.026204  0.015289  0.000000  ...  0.000000  0.000000  0.112937  0.000000   \n",
       "25  0.010957  0.012785  0.012087  ...  0.000000  0.012087  0.135763  0.000000   \n",
       "26  0.010809  0.012613  0.000000  ...  0.000000  0.000000  0.151402  0.000000   \n",
       "27  0.011076  0.012924  0.000000  ...  0.000000  0.000000  0.149172  0.000000   \n",
       "28  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "29  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "30  0.014038  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "31  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       zhang     zinke      zita   zoology   œgrant  œsupport  \n",
       "0   0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.03861  0.000000  \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "9   0.000000  0.000000  0.029843  0.029843  0.00000  0.000000  \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "15  0.000000  0.061435  0.000000  0.000000  0.00000  0.000000  \n",
       "16  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "18  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.00000  0.032552  \n",
       "20  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "21  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "22  0.029212  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "23  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "24  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "25  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "26  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "27  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "28  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "29  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "30  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "31  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "\n",
       "[32 rows x 2959 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n",
    "\n",
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:50])\n",
    "\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[:15])\n",
    "\n",
    "# Create the CountVectorizer DataFrame: count_df\n",
    "#count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avalia_resultado(y_test, y_pred):\n",
    "    print(f' Acurácia:\\t{100 * accuracy_score(y_test, y_pred):.2f} %')\n",
    "    print(\" Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred, labels=['N', 'Y']))\n",
    "    print(\" Relatório de classificação:\\n\", classification_report(y_test, y_pred, labels=['N', 'Y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação com Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X['opo_texto_sem_stop'], y, test_size=0.33)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X['opo_texto_sem_stop_lem'], y, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição de classes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treino</th>\n",
       "      <th>Teste</th>\n",
       "      <th>Treino%</th>\n",
       "      <th>Teste%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>53.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>46.153846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Treino  Teste    Treino%     Teste%\n",
       "Y      21      7  58.333333  53.846154\n",
       "N      15      6  41.666667  46.153846"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Distribuição de classes')\n",
    "dist_classes = pd.DataFrame({'Treino': dict(Counter(y_train)), 'Teste': dict(Counter(y_test))})\n",
    "dist_classes['Treino%'] = dist_classes['Treino'].div(dist_classes['Treino'].sum()).mul(100)\n",
    "dist_classes['Teste%'] = dist_classes['Teste'].div(dist_classes['Teste'].sum()).mul(100)\n",
    "dist_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes com Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "X_bow_train = count_vectorizer.fit_transform(X_train)\n",
    "X_bow_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica_NB_bow_alpha(alpha=1):\n",
    "    \"\"\"Classifica TF-DF para diferentes valores de alpha\"\"\"\n",
    "    print(f'\\n{\"-\"*45}')\n",
    "    print(f'Naive Bayes - BoW')\n",
    "    print(f'{\"-\"*45}')\n",
    "    classificador_bow = MultinomialNB(alpha=alpha)\n",
    "    classificador_bow.fit(X_bow_train, y_train)\n",
    "    y_pred_bow = classificador_bow.predict(X_bow_test)\n",
    "    avalia_resultado(y_test, y_pred_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "Naive Bayes - BoW\n",
      "---------------------------------------------\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.71      0.83      0.77         6\n",
      "          Y       0.83      0.71      0.77         7\n",
      "\n",
      "avg / total       0.78      0.77      0.77        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifica_NB_bow_alpha()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes com TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X_tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica_NB_tfidf_alpha(alpha):\n",
    "    \"\"\"Classifica TF-DF para diferentes valores de alpha\"\"\"\n",
    "    print(f'\\n{\"-\"*55}')\n",
    "    print(f'Naive Bayes - TF-IDF')\n",
    "    print(f'{\"-\"*55}\\nAlpha = {alpha:.2f}:\\n{\"-\"*55}')\n",
    "    classificador_tfidf = MultinomialNB(alpha=alpha)\n",
    "    classificador_tfidf.fit(X_tfidf_train, y_train)\n",
    "    y_pred_tfidf = classificador_tfidf.predict(X_tfidf_test)\n",
    "    avalia_resultado(y_test, y_pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.21, 0.41, 0.61, 0.81])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Varia o parâmetro alpha para checar qual o melhor\n",
    "alphas = np.arange(0.01, 1, 0.2)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------\n",
      "Naive Bayes - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Alpha = 0.01:\n",
      "-------------------------------------------------------\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.71      0.83      0.77         6\n",
      "          Y       0.83      0.71      0.77         7\n",
      "\n",
      "avg / total       0.78      0.77      0.77        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Naive Bayes - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Alpha = 0.21:\n",
      "-------------------------------------------------------\n",
      " Acurácia:\t69.23 %\n",
      " Matriz de Confusão:\n",
      " [[4 2]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.67      0.67      0.67         6\n",
      "          Y       0.71      0.71      0.71         7\n",
      "\n",
      "avg / total       0.69      0.69      0.69        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Naive Bayes - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Alpha = 0.41:\n",
      "-------------------------------------------------------\n",
      " Acurácia:\t69.23 %\n",
      " Matriz de Confusão:\n",
      " [[4 2]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.67      0.67      0.67         6\n",
      "          Y       0.71      0.71      0.71         7\n",
      "\n",
      "avg / total       0.69      0.69      0.69        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Naive Bayes - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Alpha = 0.61:\n",
      "-------------------------------------------------------\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[2 4]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.50      0.33      0.40         6\n",
      "          Y       0.56      0.71      0.63         7\n",
      "\n",
      "avg / total       0.53      0.54      0.52        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Naive Bayes - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Alpha = 0.81:\n",
      "-------------------------------------------------------\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[2 4]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.50      0.33      0.40         6\n",
      "          Y       0.56      0.71      0.63         7\n",
      "\n",
      "avg / total       0.53      0.54      0.52        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for alpha in alphas:\n",
    "    classifica_NB_tfidf_alpha(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipos_svn = ['linear', 'rbf', 'sigmoid']\n",
    "C = [0.1, 0.3, 0.6, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avalia_svm(descricao, tipo, X_train, y_train, X_test, C):\n",
    "    print(f'\\n{\"-\"*55}\\nSVM - {descricao}\\n{\"-\"*55}')\n",
    "    print(f'Kernel = {tipo}, C = {C}\\n')\n",
    "    clf = SVC(kernel=tipo, C=C)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    avalia_resultado(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM - Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.1\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[6 0]\n",
      " [3 4]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.67      1.00      0.80         6\n",
      "          Y       1.00      0.57      0.73         7\n",
      "\n",
      "avg / total       0.85      0.77      0.76        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.3\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[6 0]\n",
      " [3 4]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.67      1.00      0.80         6\n",
      "          Y       1.00      0.57      0.73         7\n",
      "\n",
      "avg / total       0.85      0.77      0.76        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.6\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[6 0]\n",
      " [3 4]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.67      1.00      0.80         6\n",
      "          Y       1.00      0.57      0.73         7\n",
      "\n",
      "avg / total       0.85      0.77      0.76        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.8\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[6 0]\n",
      " [3 4]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.67      1.00      0.80         6\n",
      "          Y       1.00      0.57      0.73         7\n",
      "\n",
      "avg / total       0.85      0.77      0.76        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.1\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.3\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.6\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[2 4]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.50      0.33      0.40         6\n",
      "          Y       0.56      0.71      0.63         7\n",
      "\n",
      "avg / total       0.53      0.54      0.52        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.8\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.71      0.83      0.77         6\n",
      "          Y       0.83      0.71      0.77         7\n",
      "\n",
      "avg / total       0.78      0.77      0.77        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.1\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.3\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.6\n",
      "\n",
      " Acurácia:\t61.54 %\n",
      " Matriz de Confusão:\n",
      " [[2 4]\n",
      " [1 6]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.67      0.33      0.44         6\n",
      "          Y       0.60      0.86      0.71         7\n",
      "\n",
      "avg / total       0.63      0.62      0.59        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.8\n",
      "\n",
      " Acurácia:\t69.23 %\n",
      " Matriz de Confusão:\n",
      " [[3 3]\n",
      " [1 6]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.75      0.50      0.60         6\n",
      "          Y       0.67      0.86      0.75         7\n",
      "\n",
      "avg / total       0.71      0.69      0.68        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for tipo in tipos_svn:\n",
    "    for c in C:\n",
    "        avalia_svm(\"Bag of Words\", tipo, X_bow_train, y_train, X_bow_test, C=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.1\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.3\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.6\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.71      0.83      0.77         6\n",
      "          Y       0.83      0.71      0.77         7\n",
      "\n",
      "avg / total       0.78      0.77      0.77        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.8\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.71      0.83      0.77         6\n",
      "          Y       0.83      0.71      0.77         7\n",
      "\n",
      "avg / total       0.78      0.77      0.77        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.1\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.3\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.6\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.8\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.1\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.3\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.6\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.8\n",
      "\n",
      " Acurácia:\t53.85 %\n",
      " Matriz de Confusão:\n",
      " [[0 6]\n",
      " [0 7]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         6\n",
      "          Y       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tipo in tipos_svn:\n",
    "    for c in C:\n",
    "        avalia_svm(\"TF-IDF\", tipo, X_tfidf_train, y_train, X_tfidf_test, C=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u495\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "from numpy.core.umath_tests import inner1d\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimadores = [5, 10, 100, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avalia_random_forest(descricao, X_train, y_train, X_test, n_est):\n",
    "    print(f'\\n{\"-\"*60}\\nRandom Forest - {descricao}\\n{\"-\"*60}')\n",
    "    print(f'No estimadores = {n_est}\\n')\n",
    "    classifier = RandomForestClassifier(n_estimators=n_est)\n",
    "    classifier.fit(X_train, y_train) \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    avalia_resultado(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 5\n",
      "\n",
      " Acurácia:\t69.23 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [3 4]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.62      0.83      0.71         6\n",
      "          Y       0.80      0.57      0.67         7\n",
      "\n",
      "avg / total       0.72      0.69      0.69        13\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 10\n",
      "\n",
      " Acurácia:\t69.23 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [3 4]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.62      0.83      0.71         6\n",
      "          Y       0.80      0.57      0.67         7\n",
      "\n",
      "avg / total       0.72      0.69      0.69        13\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 100\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.71      0.83      0.77         6\n",
      "          Y       0.83      0.71      0.77         7\n",
      "\n",
      "avg / total       0.78      0.77      0.77        13\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 500\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.71      0.83      0.77         6\n",
      "          Y       0.83      0.71      0.77         7\n",
      "\n",
      "avg / total       0.78      0.77      0.77        13\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 1000\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.71      0.83      0.77         6\n",
      "          Y       0.83      0.71      0.77         7\n",
      "\n",
      "avg / total       0.78      0.77      0.77        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_est in n_estimadores:\n",
    "    avalia_random_forest('BoW', X_bow_train, y_train, X_bow_test, n_est=n_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest -TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 5\n",
      "\n",
      " Acurácia:\t61.54 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [4 3]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.56      0.83      0.67         6\n",
      "          Y       0.75      0.43      0.55         7\n",
      "\n",
      "avg / total       0.66      0.62      0.60        13\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 10\n",
      "\n",
      " Acurácia:\t61.54 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [4 3]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.56      0.83      0.67         6\n",
      "          Y       0.75      0.43      0.55         7\n",
      "\n",
      "avg / total       0.66      0.62      0.60        13\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 100\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.71      0.83      0.77         6\n",
      "          Y       0.83      0.71      0.77         7\n",
      "\n",
      "avg / total       0.78      0.77      0.77        13\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 500\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.71      0.83      0.77         6\n",
      "          Y       0.83      0.71      0.77         7\n",
      "\n",
      "avg / total       0.78      0.77      0.77        13\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 1000\n",
      "\n",
      " Acurácia:\t76.92 %\n",
      " Matriz de Confusão:\n",
      " [[5 1]\n",
      " [2 5]]\n",
      " Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N       0.71      0.83      0.77         6\n",
      "          Y       0.83      0.71      0.77         7\n",
      "\n",
      "avg / total       0.78      0.77      0.77        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_est in n_estimadores:\n",
    "    avalia_random_forest('BoW', X_tfidf_train, y_train, X_tfidf_test, n_est=n_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
